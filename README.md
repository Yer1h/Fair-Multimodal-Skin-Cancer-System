# Fair Multimodal Deep Learning System for Skin Cancer Detection

## üìå Project Overview
This research project addresses the critical issue of algorithmic bias in automated skin cancer diagnosis. Standard datasets (like HAM10000) predominantly feature fair-skinned patients. This project develops a **Fair Multimodal Diagnostic System (FMDS)** that integrates dermoscopic images with patient metadata (age, sex, localization) and utilizes diverse data sources (Fitzpatrick17k) to improve inclusivity and accuracy.

## üéØ Research Objectives
1.  **Multimodality:** To implement a Fusion Architecture combining CNN (EfficientNetV2) for image processing and MLP for clinical metadata.
2.  **Fairness by Design:** To apply a Data-Centric AI approach by integrating underrepresented skin tones to mitigate racial bias.
3.  **Explainability (XAI):** To implement Grad-CAM visualization, ensuring the model's decisions are clinically relevant and interpretable.

## üìÖ Project Timeline & Milestones
| Phase | Milestone | Status | Completion Date |
| :--- | :--- | :--- | :--- |
| 1 | Literature Review & Problem Definition | ‚úÖ Completed | Oct 15, 2025 |
| 2 | Social Relevance Survey ($N=11$) | ‚úÖ Completed | Oct 20, 2025 |
| 3 | Data Collection & Preprocessing | ‚úÖ Completed | Nov 05, 2025 |
| 4 | **Iteration 1:** Baseline Unimodal Model | ‚ùå Failed (Low Accuracy) | Nov 10, 2025 |
| 5 | **Iteration 2:** Multimodal Fusion Dev | ‚ö†Ô∏è Integration Challenges | Nov 14, 2025 |
| 6 | **Final:** Transfer Learning (ImageNet) + Grad-CAM | ‚úÖ Success (~62% Acc) | Nov 18, 2025 |

## üõ† Methodology & Justification
### 1. Architecture Selection
We selected a **Late Fusion** architecture.
* *Justification:* Unimodal (image-only) models fail to capture the clinical context used by dermatologists. Combining structured data (age/sex) mimics real-world diagnostic procedures.

### 2. Transfer Learning Strategy
We utilized **EfficientNetV2B0** pre-trained on ImageNet.
* *Justification:* Initial training from scratch yielded poor results (~20% accuracy). Transfer learning provided the necessary feature extraction capabilities for our limited dataset size.

### 3. Data-Centric Fairness
We merged HAM10000 with Fitzpatrick17k.
* *Justification:* To actively counter the "fair skin bias" inherent in standard medical datasets.

## üìÇ Repository Structure
This repository documents the entire research process:
* `/docs` - Research proposal, survey instruments, and draft reports.
* `/notebooks` - Code evolution. Contains both the final successful model and previous experimental iterations.
* `/data` - Processed metadata CSV files used for training.
* `/results` - Visual evidence of model performance (Accuracy graphs, Grad-CAM heatmaps).

## üöÄ How to Reproduce Results
1.  Open `notebooks/final_multimodal_fusion.ipynb` in Google Colab.
2.  Upload the CSV files from the `/data` folder to your Colab session.
3.  Run the cells sequentially. The script automatically handles image downloading and processing.
4.  Execute the final cell to generate the XAI (Grad-CAM) visualization.

## üß™ Experiments & Code Evolution
This repository contains the full history of our code development, demonstrating the iterative research process:

### üìÇ `/notebooks`
* **`v1_baseline_unimodal.ipynb` (Initial Draft)**
    * *Approach:* Attempted to train a simple model on images only.
    * *Result:* Low accuracy (~20%). The model failed to generalize due to the small dataset size and lack of clinical metadata.
    
* **`v2_experiment_custom_transfer.ipynb` (Second Draft)**
    * *Hypothesis:* Tried to improve performance by transferring weights from a previously trained custom model ("Brain Transplant" method).
    * *Challenges:* Encountered technical issues with input shape compatibility (300x300 vs 224x224) and weight freezing.
    * *Conclusion:* This approach was deemed unstable for the final production environment.

* **`v3_final_solution_multimodal.ipynb` (Final Version)**
    * *Solution:* Implemented a clean **Fusion Architecture** using **EfficientNetV2B0 (ImageNet weights)**.
    * *Key Features:* * Correct data preprocessing (handling missing metadata).
        * Data-Centric fairness adjustments.
        * **Grad-CAM** implementation for XAI.
    * *Outcome:* Successful training with ~62% accuracy and clear interpretability.

---
**Author:** Nurbol Agybetov, Yermek Khaknazar, Baglan Yessenkeldi, Tokhtar Nuralin, Alisher Mukanov 

**Course:** Research Methods and Tools

**Institution:** Astana IT University

**Date:** 18 November 2025
